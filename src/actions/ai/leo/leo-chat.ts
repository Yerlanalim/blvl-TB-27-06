'use server';

import { getUser } from '@/actions/user/authed/get-user';

// ai
import { streamObject } from 'ai';
import { openai } from '@ai-sdk/openai';
import { createStreamableValue } from 'ai/rsc';
import { z } from 'zod';

// Schema for Leo responses
const leoResponseSchema = z.object({
  content: z.string().describe('–û—Ç–≤–µ—Ç Leo –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ –±–∏–∑–Ω–µ—Å–µ'),
  suggestions: z.array(z.string()).optional().describe('–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞'),
});

// Define the message interface
interface LeoMessage {
  role: 'user' | 'system' | 'assistant';
  content: string;
}

/**
 * Generate Leo AI response for business questions
 * 
 * @param userMessage - The user's message
 * @param systemPrompt - Context-aware system prompt
 * @param previousMessages - Previous chat messages for context
 * @returns Streamable AI response
 */
export const generateLeoResponse = async (
  userMessage: string,
  systemPrompt: string,
  previousMessages: LeoMessage[] = []
) => {
  'use server';

  // Get the current user
  const user = await getUser();
  if (!user) {
    console.error('User not found for Leo chat');
    return {
      object: null,
      content: null,
    };
  }

  // Create a streamable value
  const stream = createStreamableValue();

  // Build the conversation history
  const messages: LeoMessage[] = [
    {
      role: 'system',
      content: systemPrompt,
    },
  ];

  // Add previous conversation context if available (last 6 messages)
  if (previousMessages.length > 0) {
    messages.push(...previousMessages.slice(-6));
  }

  // Add the current user message
  messages.push({
    role: 'user',
    content: userMessage,
  });

  // Start the stream generation in the background
  (async () => {
    try {
      // Generate the Leo response
      const { partialObjectStream } = streamObject({
        model: openai('gpt-4o-mini-2024-07-18'),
        temperature: 0.7, // Slightly higher for more creative business advice
        messages: messages,
        schema: leoResponseSchema,
      });

      // Loop through the streamed response and update the state
      for await (const partialObject of partialObjectStream) {
        stream.update(partialObject);
      }

      // Mark the stream as completed
      stream.done();
    } catch (error) {
      console.error('Error generating Leo response:', error);
      stream.update({ 
        content: '–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è –≤–æ–∑–Ω–∏–∫–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã. –ü–æ–ø—Ä–æ–±—É–π –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –µ—â—ë —Ä–∞–∑! ü§ñ',
        suggestions: ['–ö–∞–∫ –Ω–∞—á–∞—Ç—å —Å–≤–æ–π –±–∏–∑–Ω–µ—Å?', '–ß—Ç–æ —Ç–∞–∫–æ–µ –±–∏–∑–Ω–µ—Å-–º–æ–¥–µ–ª—å?']
      });
      stream.done();
    }
  })();

  return {
    object: stream.value,
    content: null,
  };
}; 